<html>
<head>
<title>Bitcoin Daily High Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">比特币日高预测</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/bitcoin-daily-high-prediction-b7d98a433a07?source=collection_archive---------21-----------------------#2022-04-04">https://medium.com/coinmonks/bitcoin-daily-high-prediction-b7d98a433a07?source=collection_archive---------21-----------------------#2022-04-04</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="d94f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">使用机器学习分类算法来识别指示近期价格运动的价格模式。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="fe ff jo"><img src="../Images/5f329c3d5a4c7237dab8a162266f954c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MJVARA5tX2FcQsCXltBUiw.jpeg"/></div></div></figure><h1 id="2279" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated"><strong class="ak">问题介绍</strong></h1><p id="ff2c" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">比特币是当今世界上领先的数字货币，被持有者用于交易和价值储存。更广泛采用比特币的一个障碍是其价格不稳定，这造成了大多数投资者都不舒服的风险水平。为了更好地理解比特币价格波动背后的驱动因素，并为潜在投资者提供降低风险的工具，需要能够更准确地预测比特币价格变化的模型。</p><h1 id="680d" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated"><strong class="ak">项目概述</strong></h1><p id="2e31" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">大多数股票和加密货币市场价格的预测模型都是基于时间序列的，如自回归综合移动平均(ARIMA)或机器学习算法，如递归神经网络(RNN)和长期短期记忆(LSTM)。市场价格历史的技术分析是预测市场变动的时间序列方法的替代方法，因为它基于最近价格历史中的模式。众所周知的模式如W <em class="ld">边缘</em>、<em class="ld">下降</em>和<em class="ld">上升三角形</em>和<em class="ld">头肩顶</em>被用作可能价格变动的指标。基于价格模式识别的机器学习模型，而不是基于时间序列数据的预测，可以提供更多工具来更好地预测比特币波动性的变化。</p><p id="9bf9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">大约三年的比特币价格数据以csv文件的形式从Yahoo Finance下载。这些数据由雅虎在https://www.yahoofinanceapi.com/免费慷慨提供。同一时期的历史<em class="ld">恐惧和贪婪指数</em>数据通过Alternate Me在<a class="ae le" href="https://api.alternative.me/" rel="noopener ugc nofollow" target="_blank">https://api.alternative.me/</a>提供的免费API下载。该指数是当前市场状况的一个有用指标，可从多种来源计算得出，用于量化投资者对比特币的情绪和信心。Ta库用于计算历史数据集的技术指标<em class="ld">相对强度指数</em> (rsi)，随机振荡指标<em class="ld"> stoch_k </em>和<em class="ld"> stoch_d </em>。固定长度的每日价格模式是通过将多行每日高点按顺序转换为多列以在单行数据中表示一系列价格而从比特币价格历史中生成的。最后，使用50和250天的数据以及指示50 SMA值何时大于250 SMA的“Signal”标志从历史价格数据计算出一对简单移动平均值(SMA)并将其添加到训练数据集中。有关如何为机器学习编辑和准备数据的技术细节，请参见本项目的GitHub资源库<a class="ae le" href="https://github.com/jrmerwin/Udacity_data_science_Proj_4/blob/main/Merwin_Capstone.ipynb" rel="noopener ugc nofollow" target="_blank">此处的</a>。</p><h1 id="8678" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated"><strong class="ak">解决问题的策略</strong></h1><p id="2fbf" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">该项目正在探索的理念是使用机器学习算法，这种算法擅长识别分类数据中的模式，以识别与近期上涨相关的比特币价格模式。模式识别模型将使用与技术分析类似的方法，提供时间序列建模的替代技术。对于该项目，选择了XGBoost分类器算法，其是具有高性能分类历史的梯度提升树算法的实现。分类器将被训练出历史每日高价格模式，该模式具有指示随后一天的高点是否高于当前天的二进制标签。</p><h1 id="ffa4" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated"><strong class="ak">模型性能指标</strong></h1><p id="3863" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">模型性能将使用精度指标进行测量。准确性指标的计算方法是正确预测总数(真阳性和真阴性)与预测总数(真阳性、真阴性、假阳性和假阴性)之比。选择这一指标是因为模型输出是对第二天高点的二元预测，因此它有两种正确的方式(真正的正和真正的负都应被视为正确)。因此，我们希望使用准确性来调整模型，以最大化正确预测的总数，包括正面和负面预测，这与其他度量标准(如精度或召回)相反，后者侧重于正面预测的数量。</p><h1 id="1a24" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">探索性数据分析</h1><p id="8038" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">从雅虎财经下载了大约三年的比特币价格数据，作为csv文件。这些数据是雅虎在https://www.yahoofinanceapi.com/时间<a class="ae le" href="https://www.yahoofinanceapi.com/" rel="noopener ugc nofollow" target="_blank">慷慨地免费提供的。同一时期的历史恐惧和贪婪指数数据是使用位于https://api.alternative.me/</a><a class="ae le" href="https://api.alternative.me/" rel="noopener ugc nofollow" target="_blank">的Alternate Me提供的免费API下载的。该指数是当前市场状况的一个有用指标，通过各种来源计算得出，以量化投资者对比特币的情绪和情感。Ta库用于计算技术指标相对强弱指数(rsi)，以及历史数据集中的随机振荡指标stoch_k和stoch_d。固定长度的每日价格模式是从比特币价格历史中生成的，方法是将每日高点的行按顺序转置成列，以便在单行数据中表示一系列价格。最后，使用50和250天的数据以及指示50 SMA值何时大于250 SMA值的“信号”标志，从历史价格数据计算出一对简单移动平均线(SMA ),并将其添加到训练数据集中。关于如何为机器学习创建和准备数据的技术细节可以在这个项目的GitHub知识库中找到。</a></p><p id="3253" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">探索了数据集的几个方面，并测量了工程特征的最佳范围。迭代方法用于测试工程特征的一系列值，其中该系列中的每个值用于产生模型并多次测量其精度，以产生精度箱线图。</p><p id="90a6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">价格模式中包含的最佳天数</strong></p><p id="3384" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">该模型使用一组比特币的历史日高值，从中识别相关的模式，并增加第二天的日高。为了确定模式识别的最佳历史观测值数量，基本XGBoost模型在2到45天的范围内迭代，对每个天值取5个独立模型准确度分数的平均值。从结果中生成每历史天数的平均准确度分数的箱线图，以便确定最佳数量。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div class="fe ff lf"><img src="../Images/6c039d927f46f08f62ff02b4cfad79cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*Z0BfuAwxTVLsD501UmkhdA.png"/></div></figure><p id="fc25" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">该图表明，一个令人惊讶的小范围的日高点，在3和5之间，产生了大约0.73的价格预测的最佳精度。将日高点的数量增加到4个以上会导致精确度逐渐下降，直到大约30天，在这一点上，精确度稳定在大约0.68和0.7之间振荡。使用此信息，我们将继续每天观察值为4。</p><p id="4503" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">优化训练数据中包含的历史长度</strong></p><p id="2804" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在合并、计算指标以及在计算指标之前删除因出现NAs而导致的行之后，完整的数据集包含大约1000行，或略少于3年的历史比特币价格。一个数据集的图表显示，比特币的每日高点在2020年经历了一段时间的爆炸式增长(在数据集的第650天左右)，然后在2021年初稳定下来。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div class="fe ff lg"><img src="../Images/4e44a42c2d163602d6a282759cc2ea86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*q81DtswftKHvfTuEb8eGcQ.png"/></div></figure><p id="f198" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">由于该模型使用价格模式作为输入，因此包括爆炸式增长期可能无法准确反映自2021年以来我们所处的当前价值振荡期。在数据集中包含的日期范围内对模型进行迭代，以确定包含在训练数据中的最佳天数，从而获得最大的准确性。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="fe ff lh"><img src="../Images/462cae4d881c4b66b64f6b07f787cf36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2g5I2MIR72rM7QGnB_znCA.png"/></div></div></figure><p id="588c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">得到的精度图显示，通过将行数增加到375以上直到大约475，模型的精度得到了提高。增加行数超过475会导致精确度略有下降，直到我们达到大约800时，随着包含行数的增加，精确度又开始增加。由于875行的最大值给出了大约0.73的精度，这大约相当于从450行测量的精度，并且875行将达到数据集的最大限制，因此选择450行作为我们的最佳数字似乎是合理的。</p><p id="32a5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">优化简单移动平均线对</strong></p><p id="f406" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">简单移动平均线(SMA)是帮助投资者预测资产价值长期趋势的常用技术指标。通常，使用从50、100和200天生成的SMA。由于SMA是直接从历史数据集中计算的，我们可以使用迭代过程来确定特定的SMA组合是否在模型中产生不同水平的准确性。与之前使用的类似的迭代方法，用于测试SMA值范围对模型精度的影响。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="fe ff li"><img src="../Images/092c9db2af38fdcec74732ca5f09e676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHq6dkulGXqRphSxt_iNqw.png"/></div></div></figure><p id="03a6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">热图显示分数在测试的组合中基本上是随机分布的，因此SMAs将使用50天和250天的标准值。多次重复网格和每对运行更多次证实了准确性和给定对的天数之间缺乏相关性(数据未显示)。</p><h1 id="27ae" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated"><strong class="ak">方法论</strong></h1><p id="2c5f" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">所有数据处理步骤和模型拟合的准备都是使用python进行的。流程中的每一步都被模块化为一个可执行函数，代码如下。一个完整的项目代码库可以在<a class="ae le" href="https://github.com/jrmerwin/Udacity_data_science_Proj_4/blob/main/Merwin_Capstone.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><pre class="jp jq jr js fq lj lk ll lm aw ln dt"><span id="28df" class="lo kb ht lk b fv lp lq l lr ls"><em class="ld">#Functions for data processing, feature engineering, and data optimization</em><br/><br/><br/><strong class="lk hu">def</strong> cross_fold_accuracy(X, y):<br/>    '''<br/>    input - <br/>        X - the features list from training data<br/>        y - the label list from training data<br/>    output - an accuracy score<br/>    '''    <br/>    <em class="ld"># define the classifier</em><br/>    model <strong class="lk hu">=</strong> XGBClassifier()<br/>    <em class="ld"># evaluate the model with cross validation</em><br/>    cv <strong class="lk hu">=</strong> RepeatedKFold(n_splits<strong class="lk hu">=</strong>10, n_repeats<strong class="lk hu">=</strong>3, random_state<strong class="lk hu">=</strong>1)<br/>    n_scores <strong class="lk hu">=</strong> cross_val_score(model, X, y, scoring<strong class="lk hu">=</strong>'accuracy', cv<strong class="lk hu">=</strong>cv, n_jobs<strong class="lk hu">=-</strong>1, error_score<strong class="lk hu">=</strong>'raise')<br/>    <em class="ld"># print performance and return accuracy score</em><br/>    <em class="ld">#print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))</em><br/>    accuracy <strong class="lk hu">=</strong> mean(n_scores)<br/>    <br/>    <strong class="lk hu">return</strong> accuracy<br/></span><span id="1cf8" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> row_transpose(index, rows, BTC_data):<br/>    '''<br/>    input - <br/>        index - the row number of the dataset to start transposition on<br/>        rows - the number of dates (rows) to transpose into columns and add to the dataframe<br/>        BTC_data - the dataframe upoin which to act<br/>    output - a dataframe with a single row of the transposed dates and the row values of the final date in the series<br/>    '''<br/>    <em class="ld">#transpose the daily High column</em><br/>    High_row <strong class="lk hu">=</strong> pd<strong class="lk hu">.</strong>DataFrame(BTC_data['High']<strong class="lk hu">.</strong>iloc[index<strong class="lk hu">-</strong>rows:index])<br/>    High_row_T <strong class="lk hu">=</strong> High_row<strong class="lk hu">.</strong>transpose()<br/>    High_row_T <strong class="lk hu">=</strong> High_row_T<strong class="lk hu">.</strong>reset_index()<strong class="lk hu">.</strong>drop(columns<strong class="lk hu">=</strong>['index'])<br/><br/>    <em class="ld">#isolate the selected row for merging</em><br/>    row_to_merge <strong class="lk hu">=</strong> pd<strong class="lk hu">.</strong>DataFrame(BTC_data<strong class="lk hu">.</strong>iloc[index<strong class="lk hu">-</strong>1])<br/>    row_to_merge <strong class="lk hu">=</strong> row_to_merge<strong class="lk hu">.</strong>transpose()<br/>    row_to_merge <strong class="lk hu">=</strong> row_to_merge<strong class="lk hu">.</strong>reset_index()<strong class="lk hu">.</strong>drop(columns<strong class="lk hu">=</strong>['High','index'])<br/><br/>    <em class="ld">#merge and change the column names</em><br/>    merged_row <strong class="lk hu">=</strong> pd<strong class="lk hu">.</strong>concat([High_row_T, row_to_merge], axis<strong class="lk hu">=</strong>1)<br/>    <strong class="lk hu">for</strong> i <strong class="lk hu">in</strong> range(rows<strong class="lk hu">+</strong>1):<br/>        merged_row<strong class="lk hu">.</strong>rename(columns<strong class="lk hu">=</strong>{ merged_row<strong class="lk hu">.</strong>columns[i<strong class="lk hu">-</strong>1]: i }, inplace <strong class="lk hu">=</strong> <strong class="lk hu">True</strong>)<br/>        merged_row<strong class="lk hu">.</strong>columns <strong class="lk hu">=</strong> [<strong class="lk hu">*</strong>merged_row<strong class="lk hu">.</strong>columns[:<strong class="lk hu">-</strong>1], 'week_year_numeric'] <br/>    <br/>    <strong class="lk hu">return</strong> merged_row<br/></span><span id="e32f" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> iterate_dataframe(starting_index, rows, BTC_data):<br/>    '''<br/>    input - <br/>        starting_index = scalar value for starting row in dataframe, <br/>        rows = number of days (rows) prior to index to transpose, <br/>        BTC_data = dataset<br/>    output - transposed row values as columns<br/>    '''<br/>    <em class="ld">#set the parameters</em><br/>    <em class="ld">#print('iterating over rows...')</em><br/>    total_rows <strong class="lk hu">=</strong> len(BTC_data<strong class="lk hu">.</strong>index)<br/>    row_increase <strong class="lk hu">=</strong> 0<br/><br/>    <em class="ld">#Get first row</em><br/>    result <strong class="lk hu">=</strong> row_transpose(starting_index, rows, BTC_data)<br/><br/>    <em class="ld">#transpose rows</em><br/>    <strong class="lk hu">for</strong> i <strong class="lk hu">in</strong> range(starting_index,total_rows):<br/>        row_increase <strong class="lk hu">=</strong> row_increase<strong class="lk hu">+</strong>1<br/>        inter_results <strong class="lk hu">=</strong> row_transpose(starting_index<strong class="lk hu">+</strong>row_increase, rows, BTC_data)<br/>        result <strong class="lk hu">=</strong> result<strong class="lk hu">.</strong>append(inter_results)<br/>        <br/>    <em class="ld">#rename transposed columns    </em><br/>    result <strong class="lk hu">=</strong> create_label(starting_index, rows, result)<br/>    result<strong class="lk hu">.</strong>rename(columns <strong class="lk hu">=</strong> {'Day_0':'week_numeric'}, inplace <strong class="lk hu">=</strong> <strong class="lk hu">True</strong>)<br/>     <br/>    <strong class="lk hu">return</strong> result<br/></span><span id="5f0c" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> generate_lists(df):<br/>    '''<br/>    input - Dataset containing features and label identified as 'Label'<br/>    output - 'labels' = Label list, 'features' = Features list, 'feature_list' = and a list of feature names<br/>    '''<br/>    <em class="ld">#generate the labels and the features</em><br/>    labels <strong class="lk hu">=</strong> np<strong class="lk hu">.</strong>array(df['Label'])<br/>    features <strong class="lk hu">=</strong> df<strong class="lk hu">.</strong>drop('Label', axis <strong class="lk hu">=</strong> 1)<br/><br/>    <em class="ld"># Saving feature names as list</em><br/>    feature_list <strong class="lk hu">=</strong> list(features<strong class="lk hu">.</strong>columns)<br/><br/>    <em class="ld"># Convert features to array</em><br/>    features <strong class="lk hu">=</strong> np<strong class="lk hu">.</strong>array(features)<br/>    <br/>    <strong class="lk hu">return</strong> labels, features, feature_list<br/></span><span id="df2c" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> create_label(index, rows, df):<br/>    '''<br/>    input - <br/>        index - the row number to start transposition on<br/>        rows - the number of dates to transpose as columns and the dataframe<br/>        df - the dataframe upoin which to act<br/>    output - a dataframe with the final daily high value removed, repalced with a label column<br/>    '''<br/>    <em class="ld">#replace row names</em><br/>    <strong class="lk hu">for</strong> i <strong class="lk hu">in</strong> range(rows<strong class="lk hu">+</strong>1):<br/>        row_name <strong class="lk hu">=</strong> 'Day_' <strong class="lk hu">+</strong> str(i)<br/>        df<strong class="lk hu">.</strong>rename(columns<strong class="lk hu">=</strong>{ df<strong class="lk hu">.</strong>columns[i<strong class="lk hu">-</strong>1]: row_name }, inplace <strong class="lk hu">=</strong> <strong class="lk hu">True</strong>)<br/>        <br/>    <em class="ld">#drop final day and create label</em><br/>    untimate_col <strong class="lk hu">=</strong> 'Day_' <strong class="lk hu">+</strong> str(rows)<br/>    penultimat_col <strong class="lk hu">=</strong> 'Day_' <strong class="lk hu">+</strong> str((rows<strong class="lk hu">-</strong>1))<br/>    df['Pre_Label'] <strong class="lk hu">=</strong> df[untimate_col] <strong class="lk hu">-</strong> df[penultimat_col]<br/><br/>    df<strong class="lk hu">.</strong>loc[df['Pre_Label'] <strong class="lk hu">&lt;=</strong> 0, 'Label'] <strong class="lk hu">=</strong> 0 <br/>    df<strong class="lk hu">.</strong>loc[df['Pre_Label'] <strong class="lk hu">&gt;</strong> 0, 'Label'] <strong class="lk hu">=</strong> 1 <br/><br/>    <em class="ld">#clean up NAs and auxiliary columns</em><br/>    df <strong class="lk hu">=</strong> df<strong class="lk hu">.</strong>drop(columns<strong class="lk hu">=</strong>['Pre_Label', untimate_col])<br/>    df <strong class="lk hu">=</strong> df<strong class="lk hu">.</strong>dropna()<br/>        <br/>    <strong class="lk hu">return</strong> df<br/></span><span id="1957" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> SMA(data, period<strong class="lk hu">=</strong>30, column<strong class="lk hu">=</strong>'High'):<br/>    '''<br/>    input - <br/>        data - dataset containing historical daily prices<br/>        period - the number of days for which to calculate the moving average<br/>        column - the name of the column containing the value to be averaged<br/>    output - the simple moving average for the indicated period (days)<br/>    '''<br/>    <strong class="lk hu">return</strong> data[column]<strong class="lk hu">.</strong>rolling(window<strong class="lk hu">=</strong>period)<strong class="lk hu">.</strong>mean()<br/></span><span id="5391" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> SMA_minor_major(minor_SMA, major_SMA, data):<br/>    '''<br/>    input - <br/>        minor_SMA - the number of days from which the smalled SMA will be calculated<br/>        major_SMA - the number of days from which the larger SMA will be calculated<br/>        data - dataframe containing the historical price information<br/>    output - the input dataframe with simple moving average columns added for the indicated days<br/>    '''<br/>    <em class="ld">#add the 10 and 50 day</em><br/>    data['minor_SMA'] <strong class="lk hu">=</strong> SMA(data, minor_SMA)<br/>    data['major_SMA'] <strong class="lk hu">=</strong> SMA(data, major_SMA)<br/><br/>    <em class="ld"># Get buy and sell signals</em><br/>    data['Signal'] <strong class="lk hu">=</strong> np<strong class="lk hu">.</strong>where(data['minor_SMA'] <strong class="lk hu">&gt;</strong> data['major_SMA'], 1, 0)<br/>    data['Signal_vol'] <strong class="lk hu">=</strong> data['minor_SMA'] <strong class="lk hu">-</strong> data['major_SMA']<br/>    <strong class="lk hu">return</strong> data<br/></span><span id="0a5a" class="lo kb ht lk b fv lt lq l lr ls"><strong class="lk hu">def</strong> prep_for_ml(prepared_data, data_SMA_df, total_days<strong class="lk hu">=</strong>400):<br/>    '''<br/>    input - <br/>        prepared_data - a dataframe containing the features including the transposed rows as previous day high column values<br/>        data_SMA_df - a dataframe containing the calculated SMA values<br/>        total_days - value indicating the number of rows counted from the end to include in the output dataframe<br/>    output - a merged data set containing all the features and label needed for model training<br/>    '''<br/>    <em class="ld">#merge on the date</em><br/>    merged_data <strong class="lk hu">=</strong> prepared_data<strong class="lk hu">.</strong>merge(data_SMA_df, left_on<strong class="lk hu">=</strong>'date_format', right_on<strong class="lk hu">=</strong>'date_format', suffixes<strong class="lk hu">=</strong>('', '_y'))<br/>    <em class="ld">#clean up the columns and NAs</em><br/>    merged_data<strong class="lk hu">.</strong>drop(columns<strong class="lk hu">=</strong>['High', 'date_format', 'day_count_y', 'Open_y', 'Low_y', 'Close_y', 'Adj Close_y', 'Volume_y',<br/>                          'rsi_y', 'stoch_k_y', 'stoch_d_y', 'Fear_N_Greed_y', 'month_numeric_y', 'weekday_numeric_y',<br/>                          'week_month_numeric_y', 'minor_SMA_y', 'major_SMA_y', 'Signal_y'<br/>                         ], inplace<strong class="lk hu">=True</strong>)<br/>    <em class="ld">#drop the na rows</em><br/>    data_clean <strong class="lk hu">=</strong> merged_data<strong class="lk hu">.</strong>dropna()<br/>    <em class="ld">#take the most recent days (default = 400)</em><br/>    data_clean <strong class="lk hu">=</strong> data_clean<strong class="lk hu">.</strong>tail(total_days)<br/>    <strong class="lk hu">return</strong> data_clean</span></pre><h1 id="dcb4" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">建模和超参数调整</h1><p id="43d5" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">使用包括用于缩放数据的标准缩放器和XGBoost分类器的流水线来训练该模型。如下所示定义参数网格，以测试每个参数的范围，并使用GridSearch通过交叉验证拟合模型。</p><pre class="jp jq jr js fq lj lk ll lm aw ln dt"><span id="9710" class="lo kb ht lk b fv lp lq l lr ls"><em class="ld">#generate training and testing datasets</em><br/>train_features, test_features, train_labels, test_labels <strong class="lk hu">=</strong> train_test_split(features, labels, test_size <strong class="lk hu">=</strong> 0.1)<br/><br/><em class="ld">#set up pipeline</em><br/>pipe <strong class="lk hu">=</strong> Pipeline([<br/>                 ('scl', StandardScaler()),<br/>                 ('m', XGBClassifier())<br/>                ])<br/><br/><em class="ld">#define the parameter ranges as grid</em><br/>param_grid <strong class="lk hu">=</strong> {<br/>    "m__n_estimators": range(25,100,25),<br/>    'm__max_depth':range(3,10,2),<br/>    'm__min_child_weight':range(1,6,2),<br/>    'm__subsample':[i<strong class="lk hu">/</strong>10.0 <strong class="lk hu">for</strong> i <strong class="lk hu">in</strong> range(6,10)],<br/>    'm__colsample_bytree':[i<strong class="lk hu">/</strong>10.0 <strong class="lk hu">for</strong> i <strong class="lk hu">in</strong> range(6,10)],<br/>    'm__reg_alpha':[1e-5, 1e-2, 0.1, 1, 100] <br/>}<br/><br/><em class="ld">#Instantiate the cross validation grid search</em><br/>gs_cv <strong class="lk hu">=</strong> GridSearchCV(estimator<strong class="lk hu">=</strong>pipe,<br/>                     param_grid<strong class="lk hu">=</strong>param_grid,<br/>                     n_jobs<strong class="lk hu">=-</strong>1)<br/><br/><em class="ld">#fit the model</em><br/>gs_cv<strong class="lk hu">.</strong>fit(train_features, train_labels)<br/><br/><em class="ld">#report accuracy and optimal parameter values</em><br/>print("Best parameter (CV score=%0.3f):" <strong class="lk hu">%</strong> gs_cv<strong class="lk hu">.</strong>best_score_)<br/>print(gs_cv<strong class="lk hu">.</strong>best_params_)</span><span id="7f23" class="lo kb ht lk b fv lt lq l lr ls">Best parameter (CV score=0.764):<br/>{'m__colsample_bytree': 0.8, 'm__max_depth': 7, 'm__min_child_weight': 3, 'm__n_estimators': 75, 'm__reg_alpha': 0.01, 'm__subsample': 0.7}</span></pre><h1 id="e9eb" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated"><strong class="ak">结果</strong></h1><p id="5eb3" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">模型超参数的优化使其精度从0.725提高到0.764。这个值表明，该模型可以用来预测比特币未来的价格相对于今天的价格，准确率为76.4%。</p><h1 id="c365" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">结论/反思</h1><p id="710c" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">这个项目的目标是训练一个分类模型，以识别每日比特币价格历史中预测下一个每日高值增加的模式。使用XGBoost模型，表明优化后的精度为0.764。本研究调查了数据集的几个特征对模型准确性的影响，揭示了关于比特币波动性建模的有用见解。</p><p id="fa9b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">过犹不及。</strong>对数据集特征的探索揭示了在有些狭窄的空间内，存在包含在模型中的最佳数据范围。例如，准确度箱线图表明，包含3到5之间的令人惊讶的小范围日高点的a产生了最好的价格预测准确度。将日高点的数量增加到5个以上会导致准确性逐渐下降，直到大约30天，在这一点上它稳定下来并在大约0.68和0.7之间波动。</p><p id="cbc7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">了解自己的历史。</strong>对于要包括的历史数据的天数，发现了类似的小的最佳范围。准确度随着天数的增加而增加，直到450天，此时增加天数导致准确度下降。这可能是因为450天的历史对应于2021年初，当时比特币价格结束了一个爆炸式增长阶段，因此包括该日期之前的增长期的数据可能会混淆模型。最终，精确度在大约700天后开始恢复，因为它达到了2020年爆炸式增长之前的相对价格稳定阶段。</p><p id="2f41" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">平均值。用于计算训练数据中包含的一对简单移动平均线的天数似乎没有明显的趋势或模型性能的最佳范围。一个热图显示了模型在用于较小移动平均线和较大移动平均线(在本研究中分别称为次要和主要移动平均线)的日期组合范围内的准确性，该热图看起来基本上是随机的。多次重复网格和每对运行更多次证实了准确性和给定对的天数之间缺乏相关性或明显趋势(数据未显示)。虽然在数据集中包含SMAs提高了准确性，但是对于使用哪一对似乎没有明确的选择。这可能是因为所有货币对的表现都一样好，或者是因为简单移动平均线与中长期价格变化的相关性更好。</p><h1 id="b05d" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">丰富</h1><p id="4bb3" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">通过使用不同的分类算法或通过将多个单独优化的算法一起用作集成模型，模型的性能可能会得到改善。此外，虽然该模型的输出是二进制的，但预测本身是介于0和1之间的概率，这可能用历史数据来校准，以给出预测置信度和预期价格变动幅度的概念。在构建其他市场预测算法时，从上述数据和模型性能的探索中获得的见解可能是有用的考虑因素。</p><h1 id="4c13" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">参考</h1><p id="89d2" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">BTC历史数据API(免费):<a class="ae le" href="https://www.yahoofinanceapi.com/" rel="noopener ugc nofollow" target="_blank">https://www.yahoofinanceapi.com/</a><br/>另类的我恐惧与贪婪API(免费):<a class="ae le" href="https://api.alternative.me/" rel="noopener ugc nofollow" target="_blank">https://api.alternative.me/</a><br/><a class="ae le" href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/</a><br/><a class="ae le" href="https://www.machinelearningplus.com/plots/python-boxplot/" rel="noopener ugc nofollow" target="_blank">https://www.machinelearningplus.com/plots/python-boxplot/</a><br/><a class="ae le" href="https://www.journaldev.com/32984/numpy-matrix-transpose-array" rel="noopener ugc nofollow" target="_blank">https://www . journal dev . com/32984/numpy-matrix-transpose-array</a></p><blockquote class="lu"><p id="3c54" class="lv lw ht bd lx ly lz ma mb mc md jn ek translated">加入Coinmonks <a class="ae le" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae le" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解加密交易和投资</p></blockquote><h1 id="8f6f" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl me kn ko kp mf kr ks kt mg kv kw kx dt translated">另外，阅读</h1><ul class=""><li id="1a50" class="mh mi ht is b it ky ix kz jb mj jf mk jj ml jn mm mn mo mp dt translated"><a class="ae le" href="https://coincodecap.com/ftx-futures-trading" rel="noopener ugc nofollow" target="_blank">如何在FTX交易所交易期货</a> | <a class="ae le" href="https://coincodecap.com/okex-vs-binance" rel="noopener ugc nofollow" target="_blank"> OKEx vs币安</a></li><li id="bd5a" class="mh mi ht is b it mq ix mr jb ms jf mt jj mu jn mm mn mo mp dt translated"><a class="ae le" href="https://coincodecap.com/coinloan-review" rel="noopener ugc nofollow" target="_blank"> CoinLoan审查</a> | <a class="ae le" rel="noopener" href="/coinmonks/youhodler-4-easy-ways-to-make-money-98969b9689f2"> YouHodler审查</a> | <a class="ae le" href="https://coincodecap.com/blockfi-review" rel="noopener ugc nofollow" target="_blank"> BlockFi审查</a></li><li id="38cb" class="mh mi ht is b it mq ix mr jb ms jf mt jj mu jn mm mn mo mp dt translated"><a class="ae le" href="https://coincodecap.com/profittradingapp-for-binance" rel="noopener ugc nofollow" target="_blank">XT.COM评论</a>币安评论 | <a class="ae le" href="https://coincodecap.com/xt-com-review" rel="noopener ugc nofollow" target="_blank"/></li><li id="545e" class="mh mi ht is b it mq ix mr jb ms jf mt jj mu jn mm mn mo mp dt translated"><a class="ae le" href="https://coincodecap.com/smithbot-review" rel="noopener ugc nofollow" target="_blank"> SmithBot评论</a> | <a class="ae le" href="https://coincodecap.com/free-open-source-trading-bots" rel="noopener ugc nofollow" target="_blank"> 4款最佳免费开源交易机器人</a></li><li id="2000" class="mh mi ht is b it mq ix mr jb ms jf mt jj mu jn mm mn mo mp dt translated"><a class="ae le" rel="noopener" href="/coinmonks/coinbase-bots-ac6359e897f3">比特币基地僵尸程序</a> | <a class="ae le" rel="noopener" href="/coinmonks/ascendex-review-53e829cf75fa"> AscendEX审查</a> | <a class="ae le" rel="noopener" href="/coinmonks/okex-trading-bots-234920f61e60"> OKEx交易僵尸程序</a></li></ul></div></div>    
</body>
</html>